{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop Deep Learning\n",
    "## Modell Zusammenstellung und Training\n",
    "### SetUp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Jewellery'\n",
    "\n",
    "kategorien = ['Ring', 'Bracelet', 'Necklace']\n",
    "\n",
    "picture_limit = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No GPU.\n",
    "# before importing tensorflow backend\n",
    "#from __future__ import print_function\n",
    "#import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Building the CNN\n",
    "import pandas\n",
    "# set Workingdirectory\n",
    "import os\n",
    "#os.chdir(r'Path\\to\\your\\pictures')\n",
    "\n",
    "import random\n",
    "# Importing the Keras libraries and packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "#from google_images_download import google_images_download   #importing the library\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import urllib.request\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Google Bilder Download (deprecated)\n",
    "\n",
    "weitere Info: https://github.com/hardikvasa/google-images-download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(name, ignore_errors=True)\n",
    "\n",
    "response = google_images_download.googleimagesdownload()   #class instantiation\n",
    "\n",
    "if picture_limit > 100:\n",
    "    picture_limit = 100\n",
    "path_dict = {}\n",
    "#examples:\n",
    "for ka in kategorien:\n",
    "    arguments = {\"keywords\":ka,\"limit\":picture_limit,\"print_urls\":True,\n",
    "                 'output_directory':name\n",
    "                 }   #creating list of arguments\n",
    "    paths = response.download(arguments)   #passing the arguments to the function\n",
    "    path_dict[ka] = paths[0][ka]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium Bilder Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('E:\\Schulungen\\Schulung_AI\\Schulung_Bildanalyse\\Python')\n",
    "# =============================================================================\n",
    "# category = 'Schraube_Mutter'\n",
    "# path = r'E:\\Schulungen\\Schulung_AI\\Schulung_Bildanalyse\\App'\n",
    "# name = 'Sepp'\n",
    "# =============================================================================\n",
    "shutil.rmtree(name, ignore_errors=True)\n",
    "#os.mkdir(name)\n",
    "#os.chdir(name)\n",
    "\n",
    "#name = 'imagestest'\n",
    "#kategorien = ['green oil art']\n",
    "#picture_limit = 1000\n",
    "\n",
    "#category = category.replace('_',' ')\n",
    "#kategorien = [category]\n",
    "#choose_kat = kategorien[0].replace(' ','_')\n",
    "\n",
    "#path_dict = {}\n",
    "\n",
    "sys.path.insert(0,r'C:\\Program Files\\geckodriver\\geckodriver.exe')\n",
    "\n",
    "def scroll_down(scroll_pause_time, times_to_go_down, driver):\n",
    "\t\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\t\n",
    "    for i in range(times_to_go_down):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(scroll_pause_time)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "\n",
    "def get_google_images(search_term_list, number_of_photos):\n",
    "    \n",
    "    driver = webdriver.Firefox()\n",
    "    \n",
    "# =============================================================================\n",
    "# \tos.chdir('./')\n",
    "# \tif not os.path.isdir('./images'):\n",
    "# \t\tos.mkdir('./images')\n",
    "#     \n",
    "# \tfor i in search_term_list:    \n",
    "# \t\tif not os.path.isdir('./images/'+i):\n",
    "# \t\t\tos.mkdir('./images/'+i)\n",
    "# =============================================================================\n",
    "  \n",
    "#    download_dir = './data/'\n",
    "#    link_files_dir = './data/link_files/'\n",
    "#    log_dir = './logs/'\n",
    "    image_dir = './'+ name + '/'\n",
    "#    \n",
    "#    for d in [download_dir, link_files_dir, log_dir, image_dir]:\n",
    "#        if not os.path.exists(d):\n",
    "#            os.makedirs(d)  \n",
    "\n",
    "    for i in search_term_list:\n",
    "        print(i)\n",
    "        if not os.path.exists(image_dir+i):\n",
    "            os.makedirs(image_dir+i)  \n",
    "        os.chdir(image_dir+i)\n",
    "        driver.get('https://www.google.de/imghp?hl=de')\n",
    "\t\t\n",
    "        input_field = driver.find_element_by_class_name(\"gLFyf.gsfi\")\n",
    "        button = driver.find_element_by_class_name('Tg7LZd')\n",
    "        input_field.send_keys(i)\n",
    "        button.click()\n",
    "        scroll_down(1, 1, driver)\n",
    "        time.sleep(4)\n",
    "        images = driver.find_elements_by_tag_name('img')[:number_of_photos]\n",
    "        \n",
    "        for count, image in enumerate(images):\n",
    "            if count == 0:\n",
    "                continue\n",
    "            if image.get_attribute('src') != None:\n",
    "                source = image.get_attribute('src')\n",
    "            else:\n",
    "                continue\n",
    "            urllib.request.urlretrieve(source, i + str(count) + \".png\")\n",
    "        os.chdir('..')\n",
    "        \n",
    "        os.chdir('..')\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ring\n",
      "Bracelet\n",
      "Necklace\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Ring': ['Ring1.png',\n",
       "  'Ring10.png',\n",
       "  'Ring12.png',\n",
       "  'Ring13.png',\n",
       "  'Ring15.png',\n",
       "  'Ring16.png',\n",
       "  'Ring18.png',\n",
       "  'Ring19.png',\n",
       "  'Ring21.png',\n",
       "  'Ring22.png',\n",
       "  'Ring24.png',\n",
       "  'Ring25.png',\n",
       "  'Ring27.png',\n",
       "  'Ring28.png',\n",
       "  'Ring3.png',\n",
       "  'Ring30.png',\n",
       "  'Ring31.png',\n",
       "  'Ring33.png',\n",
       "  'Ring34.png',\n",
       "  'Ring36.png',\n",
       "  'Ring37.png',\n",
       "  'Ring39.png',\n",
       "  'Ring4.png',\n",
       "  'Ring40.png',\n",
       "  'Ring42.png',\n",
       "  'Ring43.png',\n",
       "  'Ring45.png',\n",
       "  'Ring46.png',\n",
       "  'Ring48.png',\n",
       "  'Ring49.png',\n",
       "  'Ring51.png',\n",
       "  'Ring52.png',\n",
       "  'Ring54.png',\n",
       "  'Ring55.png',\n",
       "  'Ring57.png',\n",
       "  'Ring58.png',\n",
       "  'Ring6.png',\n",
       "  'Ring60.png',\n",
       "  'Ring61.png',\n",
       "  'Ring63.png',\n",
       "  'Ring64.png',\n",
       "  'Ring65.png',\n",
       "  'Ring66.png',\n",
       "  'Ring67.png',\n",
       "  'Ring68.png',\n",
       "  'Ring69.png',\n",
       "  'Ring7.png',\n",
       "  'Ring70.png',\n",
       "  'Ring71.png',\n",
       "  'Ring72.png',\n",
       "  'Ring73.png',\n",
       "  'Ring74.png',\n",
       "  'Ring75.png',\n",
       "  'Ring76.png',\n",
       "  'Ring77.png',\n",
       "  'Ring78.png',\n",
       "  'Ring79.png',\n",
       "  'Ring80.png',\n",
       "  'Ring81.png',\n",
       "  'Ring82.png',\n",
       "  'Ring83.png',\n",
       "  'Ring84.png',\n",
       "  'Ring85.png',\n",
       "  'Ring86.png',\n",
       "  'Ring87.png',\n",
       "  'Ring88.png',\n",
       "  'Ring89.png',\n",
       "  'Ring9.png',\n",
       "  'Ring90.png',\n",
       "  'Ring91.png',\n",
       "  'Ring92.png',\n",
       "  'Ring93.png',\n",
       "  'Ring94.png',\n",
       "  'Ring95.png',\n",
       "  'Ring96.png',\n",
       "  'Ring98.png',\n",
       "  'Ring99.png'],\n",
       " 'Bracelet': ['Bracelet1.png',\n",
       "  'Bracelet10.png',\n",
       "  'Bracelet12.png',\n",
       "  'Bracelet13.png',\n",
       "  'Bracelet15.png',\n",
       "  'Bracelet16.png',\n",
       "  'Bracelet18.png',\n",
       "  'Bracelet19.png',\n",
       "  'Bracelet21.png',\n",
       "  'Bracelet22.png',\n",
       "  'Bracelet24.png',\n",
       "  'Bracelet25.png',\n",
       "  'Bracelet27.png',\n",
       "  'Bracelet28.png',\n",
       "  'Bracelet3.png',\n",
       "  'Bracelet30.png',\n",
       "  'Bracelet31.png',\n",
       "  'Bracelet33.png',\n",
       "  'Bracelet34.png',\n",
       "  'Bracelet36.png',\n",
       "  'Bracelet37.png',\n",
       "  'Bracelet39.png',\n",
       "  'Bracelet4.png',\n",
       "  'Bracelet40.png',\n",
       "  'Bracelet42.png',\n",
       "  'Bracelet43.png',\n",
       "  'Bracelet45.png',\n",
       "  'Bracelet46.png',\n",
       "  'Bracelet48.png',\n",
       "  'Bracelet49.png',\n",
       "  'Bracelet51.png',\n",
       "  'Bracelet52.png',\n",
       "  'Bracelet53.png',\n",
       "  'Bracelet54.png',\n",
       "  'Bracelet55.png',\n",
       "  'Bracelet56.png',\n",
       "  'Bracelet57.png',\n",
       "  'Bracelet58.png',\n",
       "  'Bracelet59.png',\n",
       "  'Bracelet6.png',\n",
       "  'Bracelet60.png',\n",
       "  'Bracelet61.png',\n",
       "  'Bracelet62.png',\n",
       "  'Bracelet63.png',\n",
       "  'Bracelet64.png',\n",
       "  'Bracelet65.png',\n",
       "  'Bracelet66.png',\n",
       "  'Bracelet67.png',\n",
       "  'Bracelet68.png',\n",
       "  'Bracelet69.png',\n",
       "  'Bracelet7.png',\n",
       "  'Bracelet70.png',\n",
       "  'Bracelet71.png',\n",
       "  'Bracelet72.png',\n",
       "  'Bracelet73.png',\n",
       "  'Bracelet74.png',\n",
       "  'Bracelet75.png',\n",
       "  'Bracelet76.png',\n",
       "  'Bracelet77.png',\n",
       "  'Bracelet78.png',\n",
       "  'Bracelet79.png',\n",
       "  'Bracelet80.png',\n",
       "  'Bracelet81.png',\n",
       "  'Bracelet82.png',\n",
       "  'Bracelet83.png',\n",
       "  'Bracelet84.png',\n",
       "  'Bracelet85.png',\n",
       "  'Bracelet87.png',\n",
       "  'Bracelet88.png',\n",
       "  'Bracelet9.png',\n",
       "  'Bracelet90.png',\n",
       "  'Bracelet91.png',\n",
       "  'Bracelet93.png',\n",
       "  'Bracelet94.png',\n",
       "  'Bracelet96.png',\n",
       "  'Bracelet97.png',\n",
       "  'Bracelet99.png'],\n",
       " 'Necklace': ['Necklace1.png',\n",
       "  'Necklace10.png',\n",
       "  'Necklace12.png',\n",
       "  'Necklace13.png',\n",
       "  'Necklace14.png',\n",
       "  'Necklace15.png',\n",
       "  'Necklace16.png',\n",
       "  'Necklace18.png',\n",
       "  'Necklace19.png',\n",
       "  'Necklace21.png',\n",
       "  'Necklace22.png',\n",
       "  'Necklace24.png',\n",
       "  'Necklace25.png',\n",
       "  'Necklace27.png',\n",
       "  'Necklace28.png',\n",
       "  'Necklace3.png',\n",
       "  'Necklace30.png',\n",
       "  'Necklace31.png',\n",
       "  'Necklace33.png',\n",
       "  'Necklace34.png',\n",
       "  'Necklace36.png',\n",
       "  'Necklace37.png',\n",
       "  'Necklace38.png',\n",
       "  'Necklace39.png',\n",
       "  'Necklace4.png',\n",
       "  'Necklace40.png',\n",
       "  'Necklace41.png',\n",
       "  'Necklace42.png',\n",
       "  'Necklace43.png',\n",
       "  'Necklace44.png',\n",
       "  'Necklace45.png',\n",
       "  'Necklace46.png',\n",
       "  'Necklace47.png',\n",
       "  'Necklace48.png',\n",
       "  'Necklace49.png',\n",
       "  'Necklace50.png',\n",
       "  'Necklace51.png',\n",
       "  'Necklace52.png',\n",
       "  'Necklace53.png',\n",
       "  'Necklace54.png',\n",
       "  'Necklace55.png',\n",
       "  'Necklace56.png',\n",
       "  'Necklace57.png',\n",
       "  'Necklace58.png',\n",
       "  'Necklace59.png',\n",
       "  'Necklace6.png',\n",
       "  'Necklace60.png',\n",
       "  'Necklace61.png',\n",
       "  'Necklace62.png',\n",
       "  'Necklace63.png',\n",
       "  'Necklace64.png',\n",
       "  'Necklace65.png',\n",
       "  'Necklace66.png',\n",
       "  'Necklace67.png',\n",
       "  'Necklace68.png',\n",
       "  'Necklace69.png',\n",
       "  'Necklace7.png',\n",
       "  'Necklace70.png',\n",
       "  'Necklace71.png',\n",
       "  'Necklace72.png',\n",
       "  'Necklace73.png',\n",
       "  'Necklace74.png',\n",
       "  'Necklace75.png',\n",
       "  'Necklace76.png',\n",
       "  'Necklace77.png',\n",
       "  'Necklace78.png',\n",
       "  'Necklace79.png',\n",
       "  'Necklace80.png',\n",
       "  'Necklace81.png',\n",
       "  'Necklace82.png',\n",
       "  'Necklace83.png',\n",
       "  'Necklace84.png',\n",
       "  'Necklace85.png',\n",
       "  'Necklace86.png',\n",
       "  'Necklace87.png',\n",
       "  'Necklace88.png',\n",
       "  'Necklace89.png',\n",
       "  'Necklace9.png',\n",
       "  'Necklace90.png',\n",
       "  'Necklace91.png',\n",
       "  'Necklace92.png',\n",
       "  'Necklace93.png',\n",
       "  'Necklace94.png',\n",
       "  'Necklace95.png',\n",
       "  'Necklace96.png',\n",
       "  'Necklace97.png',\n",
       "  'Necklace98.png',\n",
       "  'Necklace99.png']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dict = {}\n",
    "\n",
    "for i in kategorien:\n",
    "    get_google_images([i], picture_limit)\n",
    "    path_dict[i] = os.listdir(name+ '\\\\' +i)\n",
    "    \n",
    "path_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ordnerorganisation\n",
    "\n",
    "Erstellen der Ordner und Aufteilung der Bilder in Test-, Trainings- und Validierungsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 62 77\n",
      "16 62 77\n",
      "18 71 88\n"
     ]
    }
   ],
   "source": [
    "#os.chdir('E:\\Schulungen\\Schulung_AI\\Schulung_Bildanalyse\\Python')\n",
    "\n",
    "folders = ['training_set', 'test_set', 'validation_set']\n",
    "for fo in folders:\n",
    "    shutil.rmtree(name + '/' + fo, ignore_errors=True)\n",
    "    os.mkdir(name + '/' + fo)\n",
    "    for ka in kategorien:\n",
    "        os.mkdir(name + '/' + fo + '/' + ka)\n",
    "        \n",
    "# 10% validation\n",
    "# 70% Training\n",
    "# 20% Test\n",
    "\n",
    "for ka in kategorien:\n",
    "    path_dict[ka] = [i for i in path_dict[ka] if os.path.splitext(i)[1].lower() in ['.jpg','.png','.jpeg']]\n",
    "    n_pictures = len(path_dict[ka])\n",
    "    test = int(np.ceil(n_pictures*0.2))\n",
    "    train = int(np.ceil(n_pictures*0.8))\n",
    "    val = n_pictures\n",
    "    print(test,train,val)\n",
    "    for i in range(test):\n",
    "        shutil.move(name + '/' + ka + '/' + os.path.basename(path_dict[ka][i]), name + '/test_set/' + ka + '/' + os.path.basename(path_dict[ka][i]))\n",
    "    for i in range(test, train):\n",
    "        shutil.move(name + '/' + ka + '/' + os.path.basename(path_dict[ka][i]), name + '/training_set/' + ka + '/' + os.path.basename(path_dict[ka][i]))\n",
    "    for i in range(train, val):\n",
    "        shutil.move(name + '/' + ka + '/' + os.path.basename(path_dict[ka][i]), name + '/validation_set/' + ka + '/' + os.path.basename(path_dict[ka][i]))   \n",
    "    shutil.rmtree(name + '/' + ka, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# CNN\n",
    "### Pretrained Convolutional Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base_vgg16 = VGG16(\n",
    "  weights = \"imagenet\",\n",
    "  include_top = False,\n",
    "  input_shape = (150, 150, 3)\n",
    ")\n",
    "\n",
    "conv_base_vgg16.trainable = False\n",
    "\n",
    "conv_base_vgg16.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 16,828,739\n",
      "Trainable params: 2,114,051\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(conv_base_vgg16)\n",
    "\n",
    "classifier.add(Flatten(input_shape=conv_base_vgg16.output_shape[1:]))\n",
    "\n",
    "# =============================================================================\n",
    "# selbst entworfene Convolutional Layers\n",
    "#\n",
    "# # Step 1 - Convolution\n",
    "# classifier.add(Convolution2D(128, kernel_size = (3,3), strides = (3, 3), input_shape = (150,150, 3), activation = 'relu'))\n",
    "# \n",
    "# # Step 2 - Pooling\n",
    "# classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# \n",
    "# # Adding a second convolutional layer\n",
    "# classifier.add(Convolution2D(64, kernel_size = (3,3), strides = (3, 3), activation = 'relu'))\n",
    "# \n",
    "# classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# \n",
    "# # Step 3 - Flattening\n",
    "# classifier.add(Flatten())\n",
    "# \n",
    "# =============================================================================\n",
    "# Step 4 - Full connection\n",
    "\n",
    "classifier.add(Dense(units = 256, activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(units = 64, activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "# Compiling the CNN\n",
    "#classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.compile(optimizer = RMSprop(lr = 2e-5), loss ='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 images belonging to 3 classes.\n",
      "Found 10 images belonging to 3 classes.\n",
      "{'Car': 0, 'Laptop': 1, 'Smartphone': 2}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1/255,\n",
    "                                     rotation_range = 40,\n",
    "                                     width_shift_range = 0.2,\n",
    "                                     height_shift_range = 0.2,\n",
    "                                     shear_range = 0.2,\n",
    "                                     zoom_range = 0.2,\n",
    "                                     horizontal_flip = True,\n",
    "                                     vertical_flip = True,\n",
    "                                     fill_mode = \"nearest\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(name +'/training_set',\n",
    "                                                 target_size = [150,150],\n",
    "                                                 batch_size = 10, \n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(name + '/test_set',\n",
    "                                            target_size = [150,150],\n",
    "                                            batch_size = 10, \n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "classes = training_set.class_indices\n",
    "f = open(name + '/classes.txt','w')\n",
    "f.write(str(classes))\n",
    "f.close()\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "i = 0\n",
    "try:\n",
    "    os.mkdir(name + '/batch_pics')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for batch in train_datagen.flow_from_directory(name + '/test_set',\n",
    "                                      target_size = (150,150),\n",
    "                                      batch_size = 10,\n",
    "                                      class_mode = 'categorical',\n",
    "                                      save_to_dir = name + '/batch_pics'):\n",
    "    i += 1\n",
    "    if i > 20: break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### checkpoint callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Checkpoints des CNN(nach jeder Epoch wird gespeichert):\n",
    "checkpoint_dir = name + '/checkpoints'\n",
    "try:\n",
    "    os.makedirs(checkpoint_dir)\n",
    "except:\n",
    "    pass\n",
    "filepath = checkpoint_dir + \"/model.{epoch:02d}-{loss:.3f}-{acc:.2f}-{val_acc:.2f}.hdf5\"\n",
    "\n",
    "# Create checkpoint callback\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath = filepath,\n",
    "    save_weights_only = False,\n",
    "    verbose = 1,\n",
    "    save_best_only = True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-8fbc9baa0fda>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 3 steps, validate for 1 steps\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.1498 - accuracy: 0.3929 - val_loss: 1.3332 - val_accuracy: 0.3000\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 2s 670ms/step - loss: 1.0525 - accuracy: 0.4286 - val_loss: 1.2210 - val_accuracy: 0.3000\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 2s 693ms/step - loss: 0.9156 - accuracy: 0.5714 - val_loss: 1.1210 - val_accuracy: 0.3000\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 2s 660ms/step - loss: 0.9750 - accuracy: 0.5357 - val_loss: 1.0581 - val_accuracy: 0.3000\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 2s 671ms/step - loss: 0.8898 - accuracy: 0.6071 - val_loss: 0.9930 - val_accuracy: 0.5000\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 2s 647ms/step - loss: 0.7853 - accuracy: 0.6071 - val_loss: 0.9398 - val_accuracy: 0.5000\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 2s 670ms/step - loss: 0.8731 - accuracy: 0.6071 - val_loss: 0.8859 - val_accuracy: 0.5000\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 2s 674ms/step - loss: 0.7109 - accuracy: 0.7500 - val_loss: 0.8413 - val_accuracy: 0.5000\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 2s 638ms/step - loss: 0.7444 - accuracy: 0.6786 - val_loss: 0.8069 - val_accuracy: 0.7000\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 2s 674ms/step - loss: 0.6540 - accuracy: 0.8214 - val_loss: 0.7699 - val_accuracy: 0.8000\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 2s 751ms/step - loss: 0.5905 - accuracy: 0.9286 - val_loss: 0.7390 - val_accuracy: 0.7000\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 2s 762ms/step - loss: 0.5761 - accuracy: 0.8571 - val_loss: 0.7026 - val_accuracy: 0.8000\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 2s 722ms/step - loss: 0.6262 - accuracy: 0.7143 - val_loss: 0.6700 - val_accuracy: 0.9000\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 2s 713ms/step - loss: 0.5068 - accuracy: 0.8929 - val_loss: 0.6419 - val_accuracy: 1.0000\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 2s 670ms/step - loss: 0.5410 - accuracy: 0.8571 - val_loss: 0.6137 - val_accuracy: 1.0000\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 2s 655ms/step - loss: 0.5122 - accuracy: 0.8571 - val_loss: 0.5904 - val_accuracy: 1.0000\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 2s 702ms/step - loss: 0.4613 - accuracy: 0.9286 - val_loss: 0.5656 - val_accuracy: 1.0000\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 2s 666ms/step - loss: 0.5328 - accuracy: 0.8571 - val_loss: 0.5416 - val_accuracy: 1.0000\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 2s 673ms/step - loss: 0.4624 - accuracy: 0.8929 - val_loss: 0.5212 - val_accuracy: 1.0000\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 2s 701ms/step - loss: 0.4225 - accuracy: 0.9286 - val_loss: 0.5043 - val_accuracy: 1.0000\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 2s 647ms/step - loss: 0.4095 - accuracy: 0.9643 - val_loss: 0.4842 - val_accuracy: 1.0000\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 2s 645ms/step - loss: 0.3976 - accuracy: 0.9286 - val_loss: 0.4657 - val_accuracy: 1.0000\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 2s 681ms/step - loss: 0.3201 - accuracy: 0.9643 - val_loss: 0.4432 - val_accuracy: 1.0000\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 2s 662ms/step - loss: 0.3226 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 1.0000\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 2s 651ms/step - loss: 0.3580 - accuracy: 0.9286 - val_loss: 0.4115 - val_accuracy: 1.0000\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 2s 759ms/step - loss: 0.3567 - accuracy: 0.9643 - val_loss: 0.3896 - val_accuracy: 1.0000\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 2s 758ms/step - loss: 0.3229 - accuracy: 1.0000 - val_loss: 0.3729 - val_accuracy: 1.0000\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 2s 757ms/step - loss: 0.3631 - accuracy: 0.8571 - val_loss: 0.3612 - val_accuracy: 1.0000\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 2s 739ms/step - loss: 0.2878 - accuracy: 0.9286 - val_loss: 0.3485 - val_accuracy: 1.0000\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 2s 703ms/step - loss: 0.2816 - accuracy: 1.0000 - val_loss: 0.3327 - val_accuracy: 1.0000\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 2s 735ms/step - loss: 0.2976 - accuracy: 0.9643 - val_loss: 0.3301 - val_accuracy: 1.0000\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 2s 755ms/step - loss: 0.2201 - accuracy: 1.0000 - val_loss: 0.3139 - val_accuracy: 1.0000\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 2s 718ms/step - loss: 0.2875 - accuracy: 0.9286 - val_loss: 0.3035 - val_accuracy: 1.0000\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 2s 751ms/step - loss: 0.2272 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 1.0000\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 2s 724ms/step - loss: 0.2187 - accuracy: 0.9643 - val_loss: 0.2857 - val_accuracy: 1.0000\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 2s 678ms/step - loss: 0.2238 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 1.0000\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 2s 717ms/step - loss: 0.2256 - accuracy: 0.9643 - val_loss: 0.2684 - val_accuracy: 1.0000\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 2s 690ms/step - loss: 0.2218 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 1.0000\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 2s 684ms/step - loss: 0.2332 - accuracy: 0.9643 - val_loss: 0.2504 - val_accuracy: 1.0000\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 2s 719ms/step - loss: 0.2186 - accuracy: 0.9286 - val_loss: 0.2461 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20cdf5f42c8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################\n",
    "random.seed(1)\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         #steps_per_epoch = 10,\n",
    "                         epochs = 40,\n",
    "                         validation_data = test_set,\n",
    "                         #callbacks = [cp_callback]\n",
    "                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "classifier.save(name + \"/checkpoints/cnn_model.hdf5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Img_Class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
